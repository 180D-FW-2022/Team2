{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc0c3d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6734338d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[[852., 449.],\n",
      "        [910., 449.],\n",
      "        [909., 511.],\n",
      "        [851., 511.]]], dtype=float32), array([[[466., 448.],\n",
      "        [533., 448.],\n",
      "        [531., 514.],\n",
      "        [465., 514.]]], dtype=float32), array([[[858., 219.],\n",
      "        [917., 221.],\n",
      "        [915., 283.],\n",
      "        [856., 282.]]], dtype=float32), array([[[470., 203.],\n",
      "        [537., 206.],\n",
      "        [536., 272.],\n",
      "        [469., 270.]]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "image = cv2.imread('test.jpg')\n",
    "corners, ids, rejected = cv2.aruco.detectMarkers(image, arucoDict7,parameters=arucoParams)\n",
    "print(corners)\n",
    "\n",
    "image = process_frame(image)\n",
    "cv2.imshow(\"test\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c6d517c",
   "metadata": {},
   "outputs": [],
   "source": [
    "arucoDict7 = cv2.aruco.Dictionary_get(cv2.aruco.DICT_7X7_50)\n",
    "arucoDict6 = cv2.aruco.Dictionary_get(cv2.aruco.DICT_6X6_50)\n",
    "arucoParams = cv2.aruco.DetectorParameters_create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "32f3d1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('test.jpg')\n",
    "corners = np.array(corners)\n",
    "corners = corners.astype('int')\n",
    "cv2.circle(image, tuple(corners[3][0][0].astype('int')), 3, (0, 255, 0), 3)\n",
    "cv2.circle(image, tuple(corners[2][0][1].astype('int')), 3, (0, 255, 0), 3)\n",
    "cv2.circle(image, tuple(corners[1][0][3].astype('int')), 3, (0, 255, 0), 3)\n",
    "cv2.circle(image, tuple(corners[0][0][2].astype('int')), 3, (0, 255, 0), 3)\n",
    "\n",
    "cv2.imshow(\"test\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c5382687",
   "metadata": {},
   "outputs": [],
   "source": [
    "tl = tuple(corners[3][0][0].astype('int'))\n",
    "tr = tuple(corners[2][0][1].astype('int'))\n",
    "bl = tuple(corners[1][0][3].astype('int'))\n",
    "br = tuple(corners[0][0][2].astype('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "02915d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 1500\n",
    "height = 1000\n",
    "pts_src = np.array([tl, tr, bl, br])\n",
    "pts_dst = np.array([[0,0], [width,0], [0,height], [width,height]])\n",
    "h, status = cv2.findHomography(pts_src, pts_dst)\n",
    "img_warp = cv2.warpPerspective(image, h, (width,height))\n",
    "cv2.imshow(\"test\", img_warp)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e73abbb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.77972918e+00 -1.01079953e-01 -5.96404214e+02]\n",
      " [ 9.07867028e-02  1.85785909e+00 -3.87656679e+02]\n",
      " [-1.09012737e-04 -5.79933802e-06  1.00000000e+00]]\n",
      "[[[605.75 338.  ]]]\n",
      "[440 276]\n"
     ]
    }
   ],
   "source": [
    "image = cv2.imread('test2.jpg')\n",
    "image = process_frame(image)\n",
    "cv2.imshow(\"test\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94b9db54",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'calibration/calibration_matrix_webcam.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 12\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[39mwhile\u001b[39;00m(\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m      7\u001b[0m       \n\u001b[0;32m      8\u001b[0m     \u001b[39m# Capture the video frame\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     \u001b[39m# by frame\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     ret, frame \u001b[39m=\u001b[39m vid\u001b[39m.\u001b[39mread()\n\u001b[1;32m---> 12\u001b[0m     frame \u001b[39m=\u001b[39m process_frame(frame)\n\u001b[0;32m     14\u001b[0m     \u001b[39m# Display the resulting frame\u001b[39;00m\n\u001b[0;32m     15\u001b[0m     cv2\u001b[39m.\u001b[39mimshow(\u001b[39m'\u001b[39m\u001b[39mframe\u001b[39m\u001b[39m'\u001b[39m, frame)\n",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m, in \u001b[0;36mprocess_frame\u001b[1;34m(frame)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprocess_frame\u001b[39m(frame):\n\u001b[1;32m----> 2\u001b[0m     mtx \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mload(\u001b[39m'\u001b[39;49m\u001b[39mcalibration/calibration_matrix_webcam.npy\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      3\u001b[0m     dist \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mload(\u001b[39m'\u001b[39m\u001b[39mcalibration/distortion_coefficients_webcam.npy\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m     h, w \u001b[39m=\u001b[39m frame\u001b[39m.\u001b[39mshape[:\u001b[39m2\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\VMG-Common\\Pictures\\camera_stuff\\3D-Graphics-Engine-main\\.venv\\lib\\site-packages\\numpy\\lib\\npyio.py:405\u001b[0m, in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[0;32m    403\u001b[0m     own_fid \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    404\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 405\u001b[0m     fid \u001b[39m=\u001b[39m stack\u001b[39m.\u001b[39menter_context(\u001b[39mopen\u001b[39;49m(os_fspath(file), \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n\u001b[0;32m    406\u001b[0m     own_fid \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    408\u001b[0m \u001b[39m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'calibration/calibration_matrix_webcam.npy'"
     ]
    }
   ],
   "source": [
    "# run video\n",
    "vid = cv2.VideoCapture(0, cv2.CAP_DSHOW)\n",
    "vid.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "vid.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "  \n",
    "while(True):\n",
    "      \n",
    "    # Capture the video frame\n",
    "    # by frame\n",
    "    ret, frame = vid.read()\n",
    "  \n",
    "    frame = process_frame(frame)\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('frame', frame)\n",
    "      \n",
    "    # the 'q' button is set as the\n",
    "    # quitting button you may use any\n",
    "    # desired button of your choice\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "  \n",
    "vid.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a01c6114",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_frame(frame):\n",
    "    mtx = np.load('calibration/calibration_matrix_webcam.npy')\n",
    "    dist = np.load('calibration/distortion_coefficients_webcam.npy')\n",
    "    h, w = frame.shape[:2]\n",
    "    newcameramtx, roi = cv2.getOptimalNewCameraMatrix(mtx, dist, (w,h), 1, (w,h))\n",
    "    frame = cv2.undistort(frame, mtx, dist, None, newcameramtx)\n",
    "    \n",
    "    corners, ids, rejected = cv2.aruco.detectMarkers(frame, arucoDict7,parameters=arucoParams)\n",
    "    corners_v, ids_v, rejected_v = cv2.aruco.detectMarkers(frame, arucoDict6,parameters=arucoParams)\n",
    "    \n",
    "    \n",
    "    if len(corners) < 4 or len(corners_v) < 1:\n",
    "        return frame\n",
    "    tl = np.array([0,0], dtype=np.float32)\n",
    "    tr = np.array([0,0], dtype=np.float32)\n",
    "    bl = np.array([0,0], dtype=np.float32)\n",
    "    br = np.array([0,0], dtype=np.float32)\n",
    "    \n",
    "    v1 = np.array([0,0], dtype=np.float32)\n",
    "    \n",
    "    tl_index = np.where(ids == 20)[0][0]\n",
    "    tr_index = np.where(ids == 21)[0][0]\n",
    "    bl_index = np.where(ids == 22)[0][0]\n",
    "    br_index = np.where(ids == 23)[0][0]\n",
    "    \n",
    "    v1_index = np.where(ids_v == 24)[0][0]\n",
    "\n",
    "    for i in range(4):\n",
    "        tl += corners[tl_index][0][i]/4\n",
    "        tr += corners[tr_index][0][i]/4\n",
    "        bl += corners[bl_index][0][i]/4\n",
    "        br += corners[br_index][0][i]/4\n",
    "        \n",
    "        v1 += corners_v[v1_index][0][i]/4\n",
    "    \n",
    "#     cv2.circle(frame, tuple(tl.astype('int')), 3, (0, 255, 0), 3)\n",
    "#     cv2.circle(frame, tuple(tr.astype('int')), 3, (0, 255, 0), 3)\n",
    "#     cv2.circle(frame, tuple(bl.astype('int')), 3, (0, 255, 0), 3)\n",
    "#     cv2.circle(frame, tuple(br.astype('int')), 3, (0, 255, 0), 3)\n",
    "#     return frame\n",
    "\n",
    "    \n",
    "    width = 1280\n",
    "    height = 720\n",
    "    offset = 0\n",
    "    pts_src = np.array([tl, tr, bl, br])\n",
    "    pts_dst = np.array([[offset,offset], [width-offset,offset], [offset,height-offset], [width-offset,height-offset]])\n",
    "    h, status = cv2.findHomography(pts_src, pts_dst)\n",
    "    img_warp = cv2.warpPerspective(frame, h, (width,height))\n",
    "    print(h)\n",
    "    \n",
    "    v1 = v1.reshape(-1,1,2)\n",
    "    print(v1)\n",
    "    v1 = cv2.perspectiveTransform(v1, h)[0][0].astype(int)\n",
    "    v1 = v1 - [40, 40]\n",
    "    print(v1)\n",
    "    \n",
    "    v1_color = color=(255,255,0)\n",
    "    img_warp = cv2.putText(img=img_warp, text=f'({v1[0]}, {v1[1]})', org=(v1[0], v1[1]), fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=1, color=v1_color, thickness=3)\n",
    "    img_warp = cv2.circle(img_warp, (v1[0],v1[1]), radius=3, color=v1_color, thickness=3)\n",
    "    return img_warp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae001204",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1 (tags/v3.10.1:2cd268a, Dec  6 2021, 19:10:37) [MSC v.1929 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "0ee284a144210c4a6b61ba0543bd6808599a52964c4fe1526a54fa2de6504200"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
